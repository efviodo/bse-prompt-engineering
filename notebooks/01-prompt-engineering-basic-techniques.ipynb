{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbdcf83",
   "metadata": {},
   "source": [
    "<img src=\"../figures/header.png\" alt=\"Header\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fe892",
   "metadata": {},
   "source": [
    "# Prompt Engineering 01: T√©cnicas B√°sicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ebaed",
   "metadata": {},
   "source": [
    "En los √∫ltimos meses, los LLMs (Large Language Models) han demostrado ser una herramienta sumamente √∫til y poderosa para un sin fin de tareas. De hecho, medio a√±o despu√©s del lanzamiento oficial de [ChatGPT](https://openai.com/blog/chatgpt), todav√≠a estamos rascando la superficie y descubriendo nuevos usos potenciales cada semana. Pero no todo es color de rosas, estos modelos todav√≠a no son lo suficientemente desarrollados para \"leer nuestras mentes\". Por esto, necesitan recibir instrucciones claras y libres de ambig√ºedades, para ejecutar tareas de forma exitosa. En pocas palabras, si queremos liberar el verdadero potencial de los LLMs necesitamos aprender a hablar su idioma.\n",
    "\n",
    "**¬øQu√© vamos a ver en este Notebook?**\n",
    "\n",
    "En este Notebook, vamos a recorrer los principios fundamentales del Prompt Engineering y profundizaremos en algunas de las t√©cnicas m√°s utilizadas para la elaboraci√≥n de prompts. Estos principios y t√©cnicas son en su mayor√≠a agn√≥sticos al modelo de lenguaje utilizado (ChatGPT, GPT-4, LLaMA, etc.), o al menos, v√°lidos para la gran mayor√≠a de modelos generativos de tipo [Text-to-Text](https://huggingface.co/tasks/text-generation#text-to-text-generation-models).\n",
    "\n",
    "**¬øQu√© herramientas vamos a utilizar?**\n",
    "\n",
    "Por simplicidad y afinidad a la implementaci√≥n actual de los productos de Cognitive Solutions, para los ejemplos de prompts vamos a utilizar el modelo m√°s reciente de OpenAI disponible a trav√©s de la API oficial (al momento de elaborar estos tutoriales dicho modelo era `gpt-3.5-turbo`). Adem√°s, para consumir la API de OpenAI vamos a utilizar el [sdk](https://pypi.org/project/openai/) oficial, que se encuentra disponible en pypi. Para el resto, funciones y l√≥gica adicional para el procesamiento de las respuestas del modelo, vamos a utilizar puro Python y alguna librer√≠a sencilla para alg√∫n problema espec√≠fico pero que no merece la pena mencionar todav√≠a.\n",
    "\n",
    "Por √∫ltimo, es necesario contar con una API Key v√°lida con cr√©ditos disponibles para realizar llamadas a la API de Open AI. Para m√°s informaci√≥n sobre c√≥mo generar y administrar las API Key puedes revisar la secci√≥n [OpenAI API Key setup](#openai-api-setup)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313bc7b",
   "metadata": {},
   "source": [
    "## √çndice\n",
    "<a class=\"anchor\" id=\"index\"></a>\n",
    "\n",
    "1. [Setups](#setups)\n",
    "    1. [OpenAI API Key setup](#openai-api-setup)\n",
    "    2. [Import & Utils](#imports)\n",
    "2. [¬øQu√© es Prompt Engineering?](#what-is-prompt-engineering)\n",
    "3. [Abstracciones de la API de OpenAI](#openai-playground)\n",
    "4. [Principios de Prompt Engineering](#principles-of-prompt)\n",
    "    1. [Principio 1: Ser claro y espec√≠fico](#be-clear-and-specific)\n",
    "    2. [Principio 2: Darle tiempo para pensar](#time-to-think)\n",
    "    3. [Principio 3: Balancear especificidad con creatividad](#allow-creativity)\n",
    "5. [Consejos √ötiles](#tips-and-tricks)\n",
    "6. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f1f8de",
   "metadata": {},
   "source": [
    "## Setups\n",
    "<a class=\"anchor\" id=\"setups\"></a>\n",
    "\n",
    "### 1. OpenAI API Key setup\n",
    "<a class=\"anchor\" id=\"openai-api-setup\"></a>\n",
    "\n",
    "ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5116d",
   "metadata": {},
   "source": [
    "* Mostrar con capturas de pantalla o similar como configurar una API Key de OpenAI desde el panel de control para utilizar aqu√≠. Tambi√©n hacer hinca·πïie en que vamos a proveerlas nosotros a los efectos del bootcamp.\n",
    "* Mostrar como poner la API key en .env para que no quede harcodeada en el notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132ef76",
   "metadata": {},
   "source": [
    "Para simplificar el manejo de las API Keys y evitar que queden \"harcodeadas\" en este notebook, utilizamos la librer√≠a [python-dotenv](https://pypi.org/project/python-dotenv/) que permite facilmente cargar variables de entorno definidas en un archivo local. En pocas palabras, lo √∫nico que necesitamos asegurarnos es que exista un archivo de nombre `.env` en la rai≈∫ de este proyecto, con el siguiente contenido:\n",
    "\n",
    "\n",
    "```yaml\n",
    "OPENAI_API_KEY=[A_VALID_OPENAI_API_KEY]\n",
    "```\n",
    "\n",
    "\n",
    "Como parte de la secci√≥n **Import&Utils** vamos a cargar esta variable de entorno utilizando los m√©todos `load_dotenv` y `find_dotenv` de esta libreria y finalmente setear las clases correspondientes del sdk de OpenAI para que utlicen la API Key cargada en memoria. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4f52c",
   "metadata": {},
   "source": [
    "### 2. Imports & Utils\n",
    "<a class=\"anchor\" id=\"impots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f885fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')  # Be sure you have a .env file defined with your OPENAI_API_KEY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b434ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=1.0, top_p=1.0):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        top_p=top_p\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def save(path: str, text: str):\n",
    "    \"\"\"\n",
    "    Helper function to save prompts and model responses as TXT files\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(f\"{path}.txt\", \"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18a90339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       ".label {\n",
       "  color: white;\n",
       "  padding: 5px;\n",
       "}\n",
       "\n",
       ".success {background-color: #04AA6D;} /* Green */\n",
       ".info {background-color: #2196F3;} /* Blue */\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Styles:\n",
    "\n",
    "This cell is to provide CSS styles for the model badge that indicates which model was used for some \n",
    "specific prompt.\n",
    "\"\"\"\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    ".label {\n",
    "  color: white;\n",
    "  padding: 5px;\n",
    "}\n",
    "\n",
    ".success {background-color: #04AA6D;} /* Green */\n",
    ".info {background-color: #2196F3;} /* Blue */\n",
    "\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4048fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"../data/faqs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e6808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de79c6e",
   "metadata": {},
   "source": [
    "## ¬øQu√© es Prompt Engineering? \n",
    "<a class=\"anchor\" id=\"what-is-prompt-engineering\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)\n",
    "\n",
    "**Intuitivamente**, un prompt no es nada m√°s que un texto que se introduce en un Modelo de Lenguaje (LM), y ‚ÄúPrompt Engineering‚Äù (o Ingenier√≠a de Prompts) es el arte de dise√±ar dicho texto para obtener el resultado deseado. Algunas personas bromean con que los Prompts son como hechizos: un conjunto de palabras, que siguen una serie de reglas complejas y extravagantes, que logran lo imposible.\n",
    "\n",
    "M√°s all√° de la bella met√°fora, por supuesto que no hay nada magico detr√°s del Prompt Engineering. Los Modelos de Lenguaje son simplemente modelos estad√≠sticos para texto, y Prompt Engineering es simplemente un conjunto de t√©cnicas para dise√±ar un input text que contenga los tokens precisos (por ejemplo instrucciones o contexto) para orientar al modelo en la direcci√≥n indicada y generar un buen resultado (m√°s tokens o incluso una imagen). \n",
    "\n",
    "\n",
    "**Formalmente**, Prompt Engineering es el proceso integtral de dise√±ar y optimizar prompts espec√≠ficos y libres de ambiguedades, para Large Language Models (LLMs), que permitan asegurar la generaci√≥n de respuestas relevantes, precisas. Implica confecionar prompts que sean claros y concisos, y a su vez que incluyan suficiente informaci√≥n de contexto para que el modelo comprenda el input de usuario y genere una respuesta apropiada. Tambi√©n implica una comprensi√≥n profunda de las capacidades y limitaciones del modelo, y suele requerir de varias iteraciones y pruebas para alcanzar el resultado deseado.\n",
    "\n",
    "En esencia, el proceso iterativo de desarrollar prompts es muy similar al de escribir software. Si no se logra el resultado deseado, refinar el prompt y repetir hasta que se obtenga el resultado deseado.\n",
    "\n",
    "\n",
    "Dise√±ar Prompts efectivos es esencial para crear agentes conversacionales que puedan comprender y responder a consultas en lenguaje natural, de una manera que sea √∫til y atractiva para los usuarios. Adem√°s es de vital importancia para prevenir situaciones en las que el modelo pueda generar respuestas sin sentido, inapropiadas o perjudiciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f5ad8",
   "metadata": {},
   "source": [
    "## Abstracciones de la API de OpenAI\n",
    "<a class=\"anchor\" id=\"openai-playground\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)\n",
    "\n",
    "Antes de pasar a los principios fundamentales de Prompt Engineering, es importante comprender las abstracciones b√°sicas de la API de OpenAI. Esto nos permitir√° utilizar de forma m√°s efectiva la misma y obtener mejores resultados.\n",
    "\n",
    "\n",
    "De todos los servicios disponibles en la API de OpenAI, vamos a utilizar el servicio [Chat](https://platform.openai.com/docs/api-reference/chat/create) el cual permite interactuar con el modelo `gpt-3.5-turbo`, similar al modelo que alimenta la interfaz de ChatGPT.\n",
    "\n",
    "\n",
    "**Request body**\n",
    "\n",
    "Veamos los par√°metros m√°s importantes y relevantes para este tutorial, presentes en la estructura de un request a este servicio:\n",
    "\n",
    "* `model`: Identificador del modelo a utilizar (ver lista de modelos disponibles [aqu√≠](https://platform.openai.com/docs/models/model-endpoint-compatibility))\n",
    "* `messages`: Lista de mensajes contenidos en la conversaci√≥n con el servicio.\n",
    "* `temperature`: Temperatura de muestreo para la selecci√≥n de tokens (0 a 2)\n",
    "* `top_p`: Alternativa de muestreo denominada \"nucleus sampling\" (0 a 1)\n",
    "* `max_tokens`: M√°ximo de tokens a utilizar en la respuesta generada\n",
    "* `functions`: Permite definir una lista de funciones a ser llamadas por el modelo para la generaci√≥nd de la respuesta, esto permite conectar el modelo con Plugins.\n",
    "\n",
    "A modo de ejemplo, el siguiente snippet de c√≥digo Python ejemplifica como replicar esta estructura para interactuar con el sdk de openai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75de70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro, aqu√≠ tienes uno:\n",
      "\n",
      "¬øQu√© le dijo una manzana verde a una manzana roja?\n",
      "\n",
      "¬°Eres tan \"apple\" tada!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Contame un chiste sobre manzanas\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0, # this is the degree of randomness of the model's output\n",
    "    top_p=1.0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c391dc",
   "metadata": {},
   "source": [
    "La mejor forma de conocer en profundidad los par√°metros disponibles de OpenAI y sus efectos en la generaci√≥n de respuestas, es jugar con los mismos y probar diferentes valores. Sientete libre de modificar los valores en este notebook para probar variantes. Otra alternativa es hacerlo a trav√©s del API [playground](https://platform.openai.com/playground) de OpenAI que permite hacer lo mismo mediante una interfaz web.\n",
    "\n",
    "**Messages**\n",
    "En la estructura del request, `messages` es una lista de mensajes, en lugar de un √∫nico mensaje. Esto es una decisi√≥n de dise√±o deliverada que permite enviar como parte del request, todos los mensajes que componen la conversaci√≥n que estamos manteniendo con el modelo y de esta forma implementar una suerte de \"memoria\". En pocas palabras, cuando mantenemos una conversaci√≥n con un LLM como ChatGPT, no es que el modelo \"se acuerde\" de nuestra conversaci√≥n si no que por el contrario, en cada nueva invocaci√≥n se provee como parte del contexto, la conversaci√≥n mantenida anteriormente.\n",
    "\n",
    "**Message Role**\n",
    "\n",
    "Si tenemos la posibilidad de proveer toda la conversaci√≥n como parte del contexto en la invocaci√≥n al modelo, entonces como hace el modelo para distinguir entre los mensajes del usuario y los generados por el propio modelo, o incluso de las instrucciones del prompt? Para esto los mensajes tienen un campo `role` que indica que tipo de mensaje es.\n",
    "\n",
    "* `system`: Mensaje que contiene las instrucciones para el modelo, tipicamente llamado prompt.\n",
    "* `assistant`: Mensaje producido por el sistema en respuesta al prompt o mensje de ususario\n",
    "* `user`: Mensaje de usuario, tipicamente generado en respuesta a la salida del modelo para continuar una conversaci√≥n.\n",
    "\n",
    "M√°s informaci√≥n sobre los tipos de mensaje en OpenAI y el resto de los par√°metros de la API [aqu√≠](https://platform.openai.com/docs/api-reference/chat). Para los que estan pensando en Langchain y como se implementa esto, son contemplados en los [chat-models](https://blog.langchain.dev/chat-models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717370a0",
   "metadata": {},
   "source": [
    "## Principios de Prompt Engineering\n",
    "<a class=\"anchor\" id=\"principles-of-prompt\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)\n",
    "\n",
    "Intuitivamente existen tres principios detr√°s de la escritura de prompts efectivos que te guiar√°n en la generaci√≥n de los resultados que estas buscando.\n",
    "\n",
    "<img src=\"../figures/2.png\" alt=\"Principles of Prompt Engineering\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530f0e",
   "metadata": {},
   "source": [
    "## Primer Principio: Escribir instrucciones claras y espec√≠ficas (Be clear and specific)\n",
    "\n",
    "<a class=\"anchor\" id=\"be-clear-and-specific\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)\n",
    "\n",
    "La forma m√°s eficaz de obtener el resultado deseado de un LLM, es proveer instrucciones lo m√°s claras y espec√≠ficas que sea posible. Esto reduce las chances de obtener respuestas incorrectas o poco relevantes para nuestro contexto. Sin embargo, nunca confundir instrucciones claras con instrucciones cortas. En algunos escenarios, prompts m√°s largos de hecho proveen mayor claridad e informaci√≥n de contexto que le permiten al modelo generar respuestas correctas y detalladas.\n",
    "\n",
    "A continuaci√≥n vemos algunas t√°cticas que puedes seguir para escribir prompts claros y espc√≠ficos.\n",
    "\n",
    "### 1. Usar delimitadores\n",
    "\n",
    "Utilizar delimitadores en el prompt para separar las instrucciones (instrucciones al sistema) del input del usuario. Cualquier caracter es v√°ido como separador (por ejemplo simbolos de puntuaci√≥n), conviene elegir un s√≠mbolo poco frecuente para reducir la probabilidad de aparici√≥n como parte del input de usuario.\n",
    "\n",
    "* Comillas triples `‚Äú‚Äú‚Äú`\n",
    "* Triple acento (back-ticks) \\`\\`\\`\n",
    "* Gui√≥n triple (dashes) `---`\n",
    "* Numeral Triple `###`\n",
    "* Angle brackets `< >`\n",
    "* Tags XML `<tag> </tag>`\n",
    "\n",
    "Tener en cuenta que caracteres delimitadores largos o muy verbose, generan prompts m√°s largos (en cantidad de tokens), lo cual conduce a un mayor consumo de APIs y a la ves podr√≠a ser un problema con prompts que se acerquen al l√≠mite m√°ximo de tama√±o (4095 para GPT-4, m√°s info [aqu√≠](https://community.openai.com/t/chatgpt-4-context-lengths/114919/3)).\n",
    "\n",
    "Se puede utilizar el [Tokenizer](https://platform.openai.com/tokenizer) de OpenAI para verificar cuantos tokens ocupa un caracter delimitador en particular. Por ejemplo:\n",
    "\n",
    "* Comillas triples `‚Äú‚Äú‚Äú` ‚Üí 1 Token\n",
    "* Triple acento (back-ticks)  \\`\\`\\` ‚Üí 2 Tokens\n",
    "* Gui√≥n triple (dashes) `---` ‚Üí 1 Token\n",
    "* Numeral Triple `###` ‚Üí 1 Token\n",
    "* Angle brackets `< >` ‚Üí 2 Tokens\n",
    "* Tags XML `<tag></tag>` ‚Üí 5 Tokens\n",
    "\n",
    "Por otro lado, utilizar delimitadores es √∫til para evitar inyecciones de prompt, al separar expl√≠citamente las instrucciones al modelo del resto del prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516434c5",
   "metadata": {},
   "source": [
    "Veamos esta t√°ctica en la pr√°ctica con un ejemplo real. Imagine que estamos trabajando para mejorar un sitio web de comercio electr√≥nico que brinda mejores perspectivas al equipo de ventas en funci√≥n de las rese√±as de los clientes. Por ejemplo, si los compradores mencionan con frecuencia que la talla de un producto es demasiado grande o demasiado peque√±a, esto podr√≠a indicar que la tabla de tallas real no es precisa.\n",
    "\n",
    "Sin embargo, analizar manualmente las opiniones de los clientes es una tarea tediosa y que requiere mucho tiempo. Por este motivo, utilizaremos GPT-4 para examinar estas revisiones y proporcionar un resumen completo.\n",
    "\n",
    "Los siguientes ejemplos son rese√±as reales que los compradores en l√≠nea han hecho de una campera para la nieve [Columbia Men's Republic Parka (Obi-Wan Kenobi‚Ñ¢)](https://www.columbia.com/p/mens-republic-parka-obi-wan-kenobi-2049261_OWK.html). ¬°Qu√© por cierto se ve tan genial! ¬°Si no costara 500 d√≥lares, tambi√©n lo comprar√≠a!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa9824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = \"\"\"\n",
    "1 Star\n",
    "This is an over engineered waste of money\n",
    "\n",
    "Nobody is truly going to be wearing this unless your in the frozen tundra‚Ä¶. Zero mobility way to large in length‚Ä¶ Absolute waste‚Ä¶\n",
    "\n",
    "---\n",
    "5 Stars\n",
    "Incredibly warm!\n",
    "\n",
    "Incredibly warm! You won‚Äôt go wrong with this jacket!\n",
    "\n",
    "---\n",
    "5 Stars\n",
    "So warm!\n",
    "\n",
    "I am a 5‚Äù4 woman and got this men‚Äôs jacket as a gift. I moved from sunny Los √Ångeles to Detroit Michigan during the storm and this jacket saved me. I get cold easily and I was so warm while walking in the snow that I had to unzip a bit because I was getting too warm. Love that this jacket has so many pockets, I don‚Äôt even need to bring a purse cuz this jacket holds it all. The details they put into this jacket is amazing.\n",
    "\n",
    "---\n",
    "1 Star\n",
    "Waste of money great look but just not designed to be used and it‚Äôs shown by the resale value\n",
    "\n",
    "Absolutely way too bulky and does not fit as described‚Ä¶ This jacket is over engineered meaning unless your going to the polar ice caps you won‚Äôt need it. Was hoping for a solid winter jacket and this is definitely not it. Zero mobility in this with how bulky it is‚Ä¶ And I have other jackets by Columbia‚Ä¶ Also Ordered an XL just as my other jackets but this one is basically a XXL the jacket is also extremely long for no reason. Definitely will be returning this as the package also came opened and the jacket was dirty.\n",
    "\n",
    "---\n",
    "2 Stars\n",
    "Overpriced, and runs big\n",
    "\n",
    "I love Star Wars and really loved this jacket in concept. It took forever to ship and when it did finally show up the package was ripped open and the jacket was dirty and damaged. Customer service was not helpful and I kept getting kicked from chat. They wanted me to return it and rebuy while doing so meanwhile I have spent $1000 and have no jacket for most of winter. Not worth the money or the hassle. Guess I am still a north face guy.\n",
    "\n",
    "---\n",
    "5 Stars\n",
    "I love it!!\n",
    "\n",
    "A very nice parka!! Comfy and warm and it looks great! Very glad I purchased it.\n",
    "\n",
    "---\n",
    "5 Stars\n",
    "Awesome\n",
    "\n",
    "Warmest jacket I've ever had. Lots of pockets, looks excellent\n",
    "\n",
    "---\n",
    "2 Stars\n",
    "Very nice looking jacket\n",
    "\n",
    "The jacket looks really nice and is warm . The sizing chart is completely off. I would normally be a large to extra large because of wide shoulders and back (I matched the large I'm the size chart). I can almost fit 2 of me into this jacket . Definitely go a size down , maybe even 2 . If you an athletic build .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770eb92",
   "metadata": {},
   "source": [
    "Comencemos con un prompt sencillo, indicando al modelo que analice las opiniones de clientes y genere un resumen de la percepci√≥n general. Con el esp√≠ritu de hacer los ejemplos m√°s limpios y f√°ciles de leer, separaremos las instrucciones del sistema del resto de la entrada. Para hacer esto, usaremos [string literals](https://docs.python.org/3/reference/lexical_analysis.html?ref=hackernoon.com#formatted-string-literals) de Python. Adem√°s, vamos a proveer el prompt en ingl√©s, ya que los modelos suelen ser un poco m√°s robustos en este idioma. No obstante, alentamos al lector a que pruebe de cambiar las instrucciones a espa√±ol para apreciar por si mismo si hay cambios importantes en los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b10a8",
   "metadata": {},
   "source": [
    "**Prompt üí¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d218ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a list of product reviews delimited by <>.\n",
    "Analyze each reviews and provide an overview of customers satisfaction, listing \n",
    "positive and negative aspects reported by customers. \n",
    "\n",
    "<{reviews}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bedb240",
   "metadata": {},
   "source": [
    "El prompt inicial es extremadamente simple y espec√≠fico, utilizando <> para separar las instrucciones del resto de la entrada (puede usar comillas invertidas, comillas triples o cualquier otro car√°cter). A pesar de su sencillez, el modelo capta la idea y genera una respuesta correcta, identificando y enumerando los aspectos positivos y negativos mencionados por los compradores en sus valoraciones. En particular, el modelo identifica adecuadamente los aspectos destacados por los compradores como el amplio espacio de almacenamiento, la sensaci√≥n de comodidad y calidez, entre otros. Al igual que los aspectos positivos, reconoce algunas quejas de los clientes, como problemas de tama√±o y problemas con el env√≠o del producto.\n",
    "\n",
    "Notar que el modelo cita algunos aspectos que no est√°n estrictamente incluidos en las opiniones de los clientes. Por ejemplo: amplio espacio de almacenamiento. Los clientes mencionaron varios bolsillos pero nunca dijeron claramente \"amplios\" (esto es una suposici√≥n del modelo). Adem√°s, ninguno se queja espec√≠ficamente del precio de la campera. A este tipo de discrepancias e inconsistencias con los datos en el contexto, se le suelen denominar [Alucinaciones](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence) (esta es una muy leve), y es un [problema com√∫n](https://spectrum.ieee.org/ai-hallucination) de los LLMs. Lo bueno es que existen t√°cticas que ayudan a reducir estas alucinaciones. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d7ce63",
   "metadata": {},
   "source": [
    "**Response ü§ñ** &nbsp;&nbsp;<span class=\"label success\">GPT-4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad41e0",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\n",
    "Overview of customer satisfaction:\n",
    "\n",
    "Positive aspects:\n",
    "\n",
    "1. Incredibly warm and suitable for cold weather conditions.\n",
    "2. Multiple pockets providing ample storage space.\n",
    "3. Attractive design and aesthetics.\n",
    "4. Comfortable and good fit for some customers.\n",
    "\n",
    "Negative aspects:\n",
    "\n",
    "1. Over-engineered, bulky, and may not be suitable for everyday wear.\n",
    "2. Sizing issues, with some customers reporting that the jacket runs large.\n",
    "3. Poor customer service experiences, including shipping issues and unhelpful responses.\n",
    "4. Expensive and potentially not worth the price for some customers.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ed847",
   "metadata": {},
   "source": [
    "Ahora te toca a t√≠, prueba con la siguiente celda de c√≥digo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f2d713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of customers satisfaction:\n",
      "- Overall, the majority of customers seem to be satisfied with the product, as there are multiple 5-star reviews praising the jacket for being warm, comfortable, and having a nice design.\n",
      "- However, there are also a few negative reviews, with customers expressing dissatisfaction with the jacket's fit, mobility, and customer service. Some customers also felt that the jacket was overpriced.\n",
      "\n",
      "Positive aspects reported by customers:\n",
      "- The jacket is incredibly warm and can keep customers comfortable in cold weather.\n",
      "- It has multiple pockets, which is convenient and eliminates the need for a purse.\n",
      "- The details and design of the jacket are praised by customers.\n",
      "- Some customers describe the jacket as comfy, great-looking, and excellent.\n",
      "\n",
      "Negative aspects reported by customers:\n",
      "- The jacket is considered too bulky and long, leading to mobility issues.\n",
      "- Customer service was reported as unhelpful and caused inconvenience to some customers.\n",
      "- The sizing chart provided by the company was inaccurate, resulting in customers receiving jackets that were too large.\n",
      "- A few customers felt that the jacket was overpriced.\n",
      "\n",
      "Overall, while the majority of customers had positive experiences with the jacket, there are some negative aspects that customers have reported, such as fit issues and customer service problems.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb734fef",
   "metadata": {},
   "source": [
    "### 2. Usar respuestas estructuradas\n",
    "\n",
    "Es muy √∫til instruirle al modelo que genere su respuesta siguiendo un formato estructurada como pueden ser `JSON`, `XML` o cualquier otro formato dentro de los limites de comprensi√≥n del modelo. Esta t√°ctica reduce la complejidad de la respuesta, elimina jerga innecesaria y hace mucho m√°s simple el procesamiento de la respuesta de forma autom√°tica utilizando alg√∫n lenguaje de programaci√≥n como por ejemplo Python. As√≠ que volvamos a nuestro prompt inicial y actualicemos las instrucciones ahora pidi√©ndole al modelo que utilice un formato JSON en la salida, con dos listas: aspectos positivos y negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd450010",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a list of product reviews delimited by <>.\n",
    "Analyze each reviews and provide an overview of customers satisfaction, listing \n",
    "positive and negative aspects reported by customers. \n",
    "\n",
    "Provide them in JSON format with the following keys: \n",
    "positive_aspects, negative_aspects.\n",
    "\n",
    "<{reviews}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c628236",
   "metadata": {},
   "source": [
    "La nueva respuesta es m√°s espec√≠fica, con menos espacio para la creatividad y f√°cil de procesar mediante c√≥digo. Esto introduce otro aspecto cr√≠tico del prompt engineering: equilibrar la especificidad con la creatividad. Si bien ser espec√≠fico es crucial, tambi√©n es importante dejar espacio para que el modelo demuestre sus capacidades creativas. Lograr el equilibrio adecuado entre especificidad y creatividad puede conducir a resultados m√°s atractivos y √∫tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8067ef",
   "metadata": {},
   "source": [
    "**Response ü§ñ** &nbsp;&nbsp;<span class=\"label success\">GPT-4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed801846",
   "metadata": {},
   "source": [
    "```python\n",
    "{\n",
    "  \"positive_aspects\": [\n",
    "    \"Incredibly warm\",\n",
    "    \"Many pockets\",\n",
    "    \"High-quality details\",\n",
    "    \"Comfortable\",\n",
    "    \"Stylish\",\n",
    "    \"Excellent appearance\"\n",
    "  ],\n",
    "  \"negative_aspects\": [\n",
    "    \"Over-engineered\",\n",
    "    \"Bulky\",\n",
    "    \"Limited mobility\",\n",
    "    \"Sizing issues\",\n",
    "    \"Expensive\",\n",
    "    \"Poor customer service\",\n",
    "    \"Shipping issues\",\n",
    "    \"Dirty and damaged upon arrival\"\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ef3e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"positive_aspects\": [\n",
      "    \"Incredibly warm\",\n",
      "    \"Lots of pockets\",\n",
      "    \"Looks great\",\n",
      "    \"Comfy\",\n",
      "    \"Warm\",\n",
      "    \"Nice looking jacket\"\n",
      "  ],\n",
      "  \"negative_aspects\": [\n",
      "    \"Over engineered\",\n",
      "    \"Zero mobility\",\n",
      "    \"Too large in length\",\n",
      "    \"Waste of money\",\n",
      "    \"Not designed to be used\",\n",
      "    \"Bulky\",\n",
      "    \"Dirty and damaged\",\n",
      "    \"Overpriced\",\n",
      "    \"Customer service not helpful\",\n",
      "    \"Sizing chart is off\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now is your turn!\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7935c73",
   "metadata": {},
   "source": [
    "### 3. Chequear casos borde\n",
    "\n",
    "Cuando dise√±amos prompts basados en textos ingresados por un usuario, es una buena pr√°ctica asegurarse de que estos textos de entrada cumplan con ciertos criterios m√≠nimos necesarios para completar las instrucciones. Si no, devolver un mensaje de error conocido. Al hacerlo, podemos garantizar que el modelo responda de manera controlada a cualquier entrada que exceda el alcance para el cual se dise√±aron inicialmente el prompt y la aplicaci√≥n construida sobre el LLM.\n",
    "\n",
    "Por ejemplo, en la siguiente review de un comprador, se promociona una campera de otra marca. Para evitar que introduzca ruido en nuestro an√°lisis, vamos a modificar el prompt para ignorar autom√°ticamente este tipo de reviews.\n",
    "\n",
    "\n",
    "(Review adicional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca262ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_review = \"\"\"\n",
    "---\n",
    "1 Star\n",
    "Not a real Jacket\n",
    "\n",
    "Looking for a real jacket, suitable for any weather condition and ready for the highest demands? Check out our McMurdo Men‚Äôs McMurdo Parka, the best value for money on the market.\n",
    "\"\"\"\n",
    "\n",
    "reviews += additional_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c826c",
   "metadata": {},
   "source": [
    "Primero, vamos a iterar sobre el prompt que tenemos, incorporando la capacidad de distinguir entre reviews v√°lidas e inv√°lidas. La forma de hacerlo es decirle al modelo como distinguirlas (reglas) o expl√≠citamente mostrarle ejemplos de review v√°lidas e inv√°lidas. En el siguiente prompt, le indicamos al modelo que ignore las revisiones no relacionadas. Te aliento a que hagas tu propia prueba con el modelo.\n",
    "\n",
    "(Prompt intermedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151ea619",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a product review about a Columbia Jacket, delimited by \n",
    "<>.\n",
    "\n",
    "If the text is related to the product, provide an overview of customer satisfaction, listing positive and negative aspects reported by the customer. \n",
    "\n",
    "If the text is not related to the product, then simply write \\\"The provided review is not related to the product or is a Spam.\\\"\n",
    "\n",
    "{reviews}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a87365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided review is not related to the product or is a Spam.\n"
     ]
    }
   ],
   "source": [
    "# Now is your turn!\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b24ada",
   "metadata": {},
   "source": [
    "Ahora que sabemos c√≥mo validar una condici√≥n sobre la entrada, combinemos esto con el prompt original para agregar un contador de reviews ignoradas como parte de la respuesta `JSON`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7030198",
   "metadata": {},
   "source": [
    "**Prompt üí¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8343981",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a list of product reviews about a Columbia Jacket delimited by <>.\n",
    "Analyze each reviews and provide an overview of customers satisfaction, listing \n",
    "positive and negative aspects reported by customers. \n",
    "\n",
    "It may happen that some of the reviews are not strictly related to the product, in that case ignore the review, \n",
    "update a counter of ignored reviews that you will display with the rest of the output and continue with the next review. \n",
    "\n",
    "Provide them in JSON format with the following keys: \n",
    "positive_aspects, negative_aspects, ignored.\n",
    "\n",
    "<{reviews}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53f536",
   "metadata": {},
   "source": [
    "**Response ü§ñ** &nbsp;&nbsp;<span class=\"label success\">GPT-4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d042d42",
   "metadata": {},
   "source": [
    "```python\n",
    "{\n",
    "  \"positive_aspects\": [\n",
    "    \"Incredibly warm\",\n",
    "    \"Many pockets\",\n",
    "    \"Great details\",\n",
    "    \"Comfy\",\n",
    "    \"Looks great\",\n",
    "    \"Excellent appearance\"\n",
    "  ],\n",
    "  \"negative_aspects\": [\n",
    "    \"Over engineered\",\n",
    "    \"Lack of mobility\",\n",
    "    \"Too large in length\",\n",
    "    \"Bulky\",\n",
    "    \"Sizing issues\",\n",
    "    \"Poor customer service\",\n",
    "    \"Delayed shipping\",\n",
    "    \"Package received damaged and dirty\"\n",
    "  ],\n",
    "  \"ignored\": 1\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d20df",
   "metadata": {},
   "source": [
    "Mucho mejor... Tener en cuenta que este prompt se apoya en el conocimiento actual del modelo para distinguir una rese√±a sobre una campera Columbia (v√°lida) de cualquier otro texto (no v√°lida). Para este ejemplo es suficiente, pero existen t√©cnicas m√°s s√≥lidas para ense√±arle al modelo a distinguir entre entradas v√°lidas e inv√°lidas. Una de las t√©cnicas m√°s robustas es la conocida como few-shot prompting cubierta en la siguiente secci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d11704b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"positive_aspects\": [\n",
      "    \"Very warm\",\n",
      "    \"Lots of pockets\",\n",
      "    \"Looks great\",\n",
      "    \"Comfy and warm\",\n",
      "    \"Excellent parka\"\n",
      "  ],\n",
      "  \"negative_aspects\": [\n",
      "    \"Over-engineered\",\n",
      "    \"Zero mobility\",\n",
      "    \"Bulky\",\n",
      "    \"Does not fit as described\",\n",
      "    \"Long length\",\n",
      "    \"Overpriced\",\n",
      "    \"Runs big\",\n",
      "    \"Package arrived opened and dirty\",\n",
      "    \"Customer service not helpful\",\n",
      "    \"Sizing chart is off\",\n",
      "    \"Not suitable for all weather conditions\"\n",
      "  ],\n",
      "  \"ignored\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now is your turn!\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6ca3a",
   "metadata": {},
   "source": [
    "### 4. Few-shot prompting\n",
    "\n",
    "En algunos escenarios, proporcionar ejemplos de ejecuciones exitosas de la tarea y luego pedirle al modelo que la ejecute, es una estrategia inteligente para obtener resultados m√°s precisos y predecibles. Para ilustrar esta t√°ctica, pensemos moment√°neamente en una funcionalidad relacionada en el sitio web de comercio electr√≥nico. Imaginemos que ahora queremos generar autom√°ticamente un mensaje de respuesta para cada opini√≥n de cliente.\n",
    "\n",
    "Para ello, le vamos a decir al modelo c√≥mo responder a algunos ejemplos t√≠picos de reviews de productos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3739c4b1",
   "metadata": {},
   "source": [
    "**Prompt üí¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "968fa635",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a list of product reviews delimited by <>.\n",
    "Analyze each review and provide a personalized answer for each one, based on the content of the review.\n",
    "\n",
    "Here is a few examples:\n",
    "\n",
    "---\n",
    "Review: I am very happy with this jacket, it is worth every penny\n",
    "Response: Thank you for your review, we are very happy that you are satisfied with our products.\n",
    "\n",
    "---\n",
    "Review: I normally wear Columbia size L jackets, this in L is like an XL. I reordered the M‚Ä¶ unfortunately the blue was not longer available =(\n",
    "Response: Thank you for your review! We are continuously working to bring you a better shopping experience and innovative products that will surprise you.\n",
    "\n",
    "---\n",
    "Review: Nobody is truly going to be wearing this unless your in the frozen tundra‚Ä¶. Zero mobility way to large in length‚Ä¶ Absolute waste‚Ä¶\n",
    "Response: Thank you for your review, the feedback from our users represents an invaluable asset for us that allows us to work to improve each product and bring you a better shopping experience. \n",
    "\n",
    "Provide them in JSON format with the following keys: review, response. Where review is the first 10 words of the customer \n",
    "review to easy identify it and response is the generated response.\n",
    "\n",
    "<{reviews}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41663258",
   "metadata": {},
   "source": [
    "N√≥tese que el modelo genera diferentes respuestas, seg√∫n el mensaje del usuario, con un tono similar a los ejemplos proporcionados. Puedes ampliar la lista de ejemplos proporcionados en el prompt, para mostrarle al modelo c√≥mo actuar en diferentes circunstancias si quieres. Adem√°s, tenga en cuenta que el modelo no sigue estrictamente nuestras especificaciones. El resumen de la revisi√≥n tiene una extensi√≥n de cinco palabras en lugar de diez. Esto puede indicar que todav√≠a tenemos que trabajar en nuestro prompt para que sea m√°s claro y espec√≠fico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ec701",
   "metadata": {},
   "source": [
    "**Response ü§ñ** &nbsp;&nbsp;<span class=\"label success\">GPT-4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e2789",
   "metadata": {},
   "source": [
    "```python\n",
    "{\n",
    "  \"1\": {\n",
    "    \"review\": \"This is an over engineered waste\",\n",
    "    \"response\": \"Thank you for your review. We're sorry that the product didn't meet your expectations. We value your feedback and will consider it for future product improvements.\"\n",
    "  },\n",
    "  \"2\": {\n",
    "    \"review\": \"Nobody is truly going to\",\n",
    "    \"response\": \"Thank you for your review. We apologize if the product didn't meet your needs. We appreciate your feedback and will use it to improve our products and ensure they cater to a wider range of customers.\"\n",
    "  },\n",
    "  \"3\": {\n",
    "    \"review\": \"Incredibly warm! You won‚Äôt\",\n",
    "    \"response\": \"Thank you for your review! We're glad to hear that you're happy with the warmth of the jacket. We hope it continues to serve you well in the colder months!\"\n",
    "  },\n",
    "  \"4\": {\n",
    "    \"review\": \"I am a 5‚Äù4 woman\",\n",
    "    \"response\": \"Thank you for your review! It's great to hear that the jacket has been keeping you warm and you're enjoying the many pockets. We appreciate your feedback and hope the jacket continues to serve you well!\"\n",
    "  },\n",
    "  \"5\": {\n",
    "    \"review\": \"Absolutely way too bulky and\",\n",
    "    \"response\": \"Thank you for your review. We apologize for the inconvenience you've experienced with the sizing and bulkiness of the jacket. Your feedback is important to us, and we'll take it into consideration for future product improvements.\"\n",
    "  },\n",
    "  \"6\": {\n",
    "    \"review\": \"I love Star Wars and\",\n",
    "    \"response\": \"Thank you for your review. We're sorry to hear about the issues you experienced with shipping and customer service. Your feedback is valuable to us, and we'll work on improving our processes to provide a better experience in the future.\"\n",
    "  },\n",
    "  \"7\": {\n",
    "    \"review\": \"A very nice parka!! Comfy\",\n",
    "    \"response\": \"Thank you for your review! We're happy to hear that you're enjoying the comfort and warmth of the parka. We hope it continues to serve you well in the colder months!\"\n",
    "  },\n",
    "  \"8\": {\n",
    "    \"review\": \"Warmest jacket I've ever had.\",\n",
    "    \"response\": \"Thank you for your review! It's great to hear that this is the warmest jacket you've ever had. We hope you continue to enjoy its warmth and style during the colder months!\"\n",
    "  },\n",
    "  \"9\": {\n",
    "    \"review\": \"The jacket looks really nice\",\n",
    "    \"response\": \"Thank you for your review. We apologize for the issues you experienced with sizing. We appreciate your feedback and will use it to improve our sizing charts to better accommodate customers with different body types.\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d37f9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"review\": \"This is an\",\n",
      "    \"response\": \"Thank you for your review, the feedback from our users represents an invaluable asset for us that allows us to work to improve each product and bring you a better shopping experience.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"Incredibly warm\",\n",
      "    \"response\": \"Thank you for your review! We are very happy that you are satisfied with our products.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"So warm! I\",\n",
      "    \"response\": \"Thank you for your review, we are very happy that you are satisfied with our products.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"Waste of money\",\n",
      "    \"response\": \"Thank you for your review, the feedback from our users represents an invaluable asset for us that allows us to work to improve each product and bring you a better shopping experience.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"Overpriced, and runs\",\n",
      "    \"response\": \"Thank you for your review, we are continuously working to bring you a better shopping experience and innovative products that will surprise you.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"I love it!!\",\n",
      "    \"response\": \"Thank you for your review, we are very happy that you are satisfied with our products.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"Awesome\\n\\nWarmest jacket I've\",\n",
      "    \"response\": \"Thank you for your review, we are very happy that you are satisfied with our products.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"Very nice\",\n",
      "    \"response\": \"Thank you for your review, we are continuously working to bring you a better shopping experience and innovative products that will surprise you.\"\n",
      "  },\n",
      "  {\n",
      "    \"review\": \"Not a real\",\n",
      "    \"response\": \"Thank you for your review, we are very happy that you are satisfied with our products.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Now is your turn!\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a30069",
   "metadata": {},
   "source": [
    "## Segundo Principio: Darle al modelo tiempo para pensar (Instruct to think)\n",
    "<a class=\"anchor\" id=\"time-to-think\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)\n",
    "\n",
    "Si se le proporciona al modelo un problema que es demasiado complejo, es posible que el modelo necesite m√°s tiempo para pensar en una respuesta adecuada. Esto significa gastar m√°s tiempo computacional para generar la respuesta y tambi√©n usar m√°s tokens tanto en el contexto como en la respuesta. Puedes pensar en esto como pedirle al modelo que organice su proceso de razonamiento de una manera particular, por ejemplo, siguiendo una serie de pasos o realizando ciertas tareas antes de generar una respuesta final. Pero sobre todo, use m√°s tokens en la respuesta y procesarla durante m√°s ciclos de c√≥mputo.\n",
    "\n",
    "Aqu√≠ hay algunas t√°cticas que se pueden usar para indicarle al modelo que piense m√°s antes de generar una respuesta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29fd71",
   "metadata": {},
   "source": [
    "### 1. Indicar los pasos para completar la tarea\n",
    "\n",
    "La primera t√°ctica, consiste en proporcionar al modelo una lista completa de pasos para resolver la tarea, cuanto m√°s espec√≠ficos sean los pasos, mejor. Volvamos a las reviews de nuestros compradores y reescribamos el prompt all modelo para hacer ambas cosas: obtener informaci√≥n de los clientes y responder a las reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a985b7",
   "metadata": {},
   "source": [
    "**Prompt üí¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba549a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Analyze the following product reviews delimited by \n",
    "  <> and summary each review with 1 sentence.\n",
    "2 - Categorize the opinion according to the following categories: super happy, happy, neutral, upset\n",
    "3 - Provide an overview of the customer satisfaction, listing positive and negative aspects mentioned in the review\n",
    "4 - Provide a personalized answer for each one, based on the content of the review.\n",
    "5 - Output a json list object that contains the \n",
    "  following keys for each review: summary, category, insights, answer.\n",
    "\n",
    "Text: <{reviews}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d925a0",
   "metadata": {},
   "source": [
    "Para este ejemplo no utilic√© todas las reviews que tenemos, para reducir la longitud de la respuesta, ya que el l√≠mite de la longitud de la respuesta dejaba algunas revisiones sin analizar en la salida del modelo (hay formas m√°s pr√°cticas de resolver este problema pero no se encuentran dentro del alcance de este tutorial). A pesar de eso, puede verificar que el modelo genera respuestas a las reviews m√°s concisas y las comprende mejor extrayendo informaci√≥n clave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc107c",
   "metadata": {},
   "source": [
    "**Response ü§ñ** &nbsp;&nbsp;<span class=\"label success\">GPT-4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ce0d9",
   "metadata": {},
   "source": [
    "```python\n",
    "[\n",
    "  {\n",
    "    \"summary\": \"Reviewer thinks the jacket is an over-engineered waste of money with zero mobility.\",\n",
    "    \"category\": \"upset\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [],\n",
    "      \"negative\": [\n",
    "        \"over engineered\",\n",
    "        \"zero mobility\",\n",
    "        \"large in length\"\n",
    "      ]\n",
    "    },\n",
    "    \"answer\": \"We're sorry to hear that you found the jacket to be over-engineered and uncomfortable. We appreciate your feedback and will take it into consideration for future improvements.\"\n",
    "  },\n",
    "  {\n",
    "    \"summary\": \"Reviewer finds the jacket incredibly warm.\",\n",
    "    \"category\": \"super happy\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [\n",
    "        \"incredibly warm\"\n",
    "      ],\n",
    "      \"negative\": []\n",
    "    },\n",
    "    \"answer\": \"We're thrilled to know that you're enjoying the warmth of the jacket! Thanks for sharing your positive experience.\"\n",
    "  },\n",
    "  {\n",
    "    \"summary\": \"Reviewer loves the warmth, pockets, and details of the jacket.\",\n",
    "    \"category\": \"super happy\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [\n",
    "        \"warm\",\n",
    "        \"many pockets\",\n",
    "        \"amazing details\"\n",
    "      ],\n",
    "      \"negative\": []\n",
    "    },\n",
    "    \"answer\": \"We're glad that you love the jacket's warmth, pockets, and attention to detail. It's great to know that it has served you well during the cold weather in Detroit!\"\n",
    "  },\n",
    "  {\n",
    "    \"summary\": \"Reviewer complains about the jacket being too bulky, not fitting as described, and receiving a dirty product.\",\n",
    "    \"category\": \"upset\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [],\n",
    "      \"negative\": [\n",
    "        \"too bulky\",\n",
    "        \"does not fit as described\",\n",
    "        \"dirty\"\n",
    "      ]\n",
    "    },\n",
    "    \"answer\": \"We apologize for the inconvenience caused by the sizing and cleanliness issues. We appreciate your feedback and will work on improving these aspects. Please feel free to return the jacket for a refund or exchange.\"\n",
    "  },\n",
    "  {\n",
    "    \"summary\": \"Reviewer loves the parka, saying it's comfy, warm, and looks great.\",\n",
    "    \"category\": \"super happy\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [\n",
    "        \"comfy\",\n",
    "        \"warm\",\n",
    "        \"looks great\"\n",
    "      ],\n",
    "      \"negative\": []\n",
    "    },\n",
    "    \"answer\": \"We're happy to hear that you love the parka's comfort, warmth, and style. Thank you for your positive review!\"\n",
    "  },\n",
    "  {\n",
    "    \"summary\": \"Reviewer thinks the jacket is the warmest they've ever had, with lots of pockets and an excellent look.\",\n",
    "    \"category\": \"super happy\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [\n",
    "        \"warmest jacket\",\n",
    "        \"lots of pockets\",\n",
    "        \"looks excellent\"\n",
    "      ],\n",
    "      \"negative\": []\n",
    "    },\n",
    "    \"answer\": \"We're delighted that you find our jacket to be the warmest you've ever had, and that you appreciate the pockets and style. Thank you for sharing your experience!\"\n",
    "  },\n",
    "  {\n",
    "    \"summary\": \"Reviewer likes the look and warmth of the jacket but finds the sizing chart off.\",\n",
    "    \"category\": \"neutral\",\n",
    "    \"insights\": {\n",
    "      \"positive\": [\n",
    "        \"nice looking\",\n",
    "        \"warm\"\n",
    "      ],\n",
    "      \"negative\": [\n",
    "        \"sizing chart off\"\n",
    "      ]\n",
    "    },\n",
    "    \"answer\": \"We appreciate your feedback on the jacket's look and warmth. We apologize for the sizing issue and will work to improve the accuracy of our sizing chart. Please consider exchanging for a better fit if needed.\"\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c40ee219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Summary of reviews:\n",
      "- 1 Star: Over engineered and not practical for everyday use.\n",
      "- 5 Stars: Incredibly warm and a great jacket choice.\n",
      "- 5 Stars: Saved the reviewer from the cold weather and has many pockets.\n",
      "- 1 Star: Bulky, over engineered, and doesn't fit properly with zero mobility.\n",
      "- 2 Stars: Overpriced, damaged package, and poor customer service.\n",
      "- 5 Stars: Comfy, warm, and looks great.\n",
      "- 5 Stars: Warmest jacket with lots of pockets, looks excellent.\n",
      "- 2 Stars: Nice looking jacket but sizing is off.\n",
      "- 1 Star: Not a real jacket, misleading advertisement.\n",
      "\n",
      "2 - Categorization of opinions:\n",
      "- 1 Star reviews: Upset\n",
      "- 5 Stars reviews: Super happy\n",
      "- 2 Stars reviews: Upset\n",
      "- 3 Stars review: Neutral\n",
      "\n",
      "3 - Customer satisfaction overview:\n",
      "Positive aspects: The jacket is incredibly warm, has many pockets, looks great, and is comfortable.\n",
      "Negative aspects: The jacket is over engineered, bulky, does not fit properly, has zero mobility, and there were issues with the package and customer service.\n",
      "\n",
      "4 - Personalized answers:\n",
      "- 1 Star review: We apologize for your experience. Our jacket is designed for extreme weather conditions, but we understand it may not suit everyone's needs. We'll work on improving our sizing, mobility, and service.\n",
      "- 5 Stars review: Thank you for your kind words! We're glad our jacket kept you warm and met your expectations. We appreciate your support.\n",
      "- 2 Stars review: We're sorry for the inconvenience. Please contact our customer service again for a resolution. We apologize for any frustration caused.\n",
      "- 3 Stars review: Thank you for your feedback. We'll take your comments into consideration for future improvements. If you have any specific concerns, please reach out to us.\n",
      "\n",
      "5 - JSON output:\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"summary\": \"Over engineered waste of money\",\n",
      "    \"category\": \"upset\",\n",
      "    \"insights\": \"Bulky, over engineered, poor fit.\",\n",
      "    \"answer\": \"We apologize for your experience. Our jacket is designed for extreme weather conditions, but we understand it may not suit everyone's needs. We'll work on improving our sizing, mobility, and service.\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"Incredibly warm!\",\n",
      "    \"category\": \"super happy\",\n",
      "    \"insights\": \"Great warmth, highly recommended.\",\n",
      "    \"answer\": \"Thank you for your kind words! We're glad our jacket kept you warm and met your expectations. We appreciate your support.\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"So warm!\",\n",
      "    \"category\": \"super happy\",\n",
      "    \"insights\": \"Saved the reviewer from cold weather, many pockets.\",\n",
      "    \"answer\": \"Thank you for your positive feedback! We're glad our jacket kept you warm and provided convenience with the pockets. Stay cozy!\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"Waste of money and poor fit\",\n",
      "    \"category\": \"upset\",\n",
      "    \"insights\": \"Bulky, poor fit, bad customer service.\",\n",
      "    \"answer\": \"We're sorry for the inconvenience. Please contact our customer service again for a resolution. We apologize for any frustration caused.\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"Overpriced and damaged package\",\n",
      "    \"category\": \"upset\",\n",
      "    \"insights\": \"Poor customer service, damaged package.\",\n",
      "    \"answer\": \"We apologize for the issues you encountered. Please reach out to our customer service again, and we'll assist you with a solution. We're sorry for the inconvenience caused.\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"I love it!!\",\n",
      "    \"category\": \"super happy\",\n",
      "    \"insights\": \"Comfy, warm, and looks great.\",\n",
      "    \"answer\": \"Thank you for your wonderful feedback! We're thrilled to hear that our jacket provided comfort, warmth, and style. Enjoy!\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"Awesome\",\n",
      "    \"category\": \"super happy\",\n",
      "    \"insights\": \"Warmest jacket, excellent looks, lots of pockets.\",\n",
      "    \"answer\": \"We're delighted to know that you're loving our jacket! The warmth, style, and functionality are key features we aim for. Thanks for sharing your experience.\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"Very nice looking jacket\",\n",
      "    \"category\": \"neutral\",\n",
      "    \"insights\": \"Nice appearance, sizing chart is off.\",\n",
      "    \"answer\": \"Thank you for your feedback! We'll take note of the sizing concerns. If you have any specific queries or need assistance, feel free to contact us.\"\n",
      "  },\n",
      "  {\n",
      "    \"summary\": \"Not a real Jacket\",\n",
      "    \"category\": \"upset\",\n",
      "    \"insights\": \"Misleading advertisement for a real jacket.\",\n",
      "    \"answer\": \"We apologize for any confusion caused. Our McMurdo Men's Parka is designed for various weather conditions and is built to withstand demanding environments. If you have any further questions, please let us know.\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Now is your turn!\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3abca1",
   "metadata": {},
   "source": [
    "### 2. Indicarle al modelo que piense su propia soluci√≥n, antes de apresuar una conclusi√≥n\n",
    "\n",
    "La segunda t√°ctica es similar a la anterior, pero adem√°s le pide al modelo que primero llegue a una soluci√≥n por s√≠ mismo antes de arrojar de forma prematura una conclusi√≥n. Esto es similar a, en lugar de indicarle al modelo que diga si algo es correcto o incorrecto seg√∫n el contexto, indicarle al modelo que primero trabaje en su propia soluci√≥n seg√∫n el contexto y luego la compare con la informaci√≥n provista como parte de la entrada para arrojar la soluci√≥n final.\n",
    "\n",
    "Por ejemplo, si la tarea es validar las respuestas de estudiantes para un problema matem√°tico simple como `2 + x = 4` y luego `x=?`, ser√≠a indicarle al modelo que primero encuentre una soluci√≥n por s√≠ mismo a este problema y luego la compare con la soluci√≥n del estudiante.\n",
    "\n",
    "Para ilustrar el poder de esta t√°ctica, exploramos otra caracter√≠stica del sitio web de comercio electr√≥nico: el procesamiento de devoluciones y reembolsos de compras. La idea es darle al modelo una lista de las demandas por reembolsos, procesar y evaluar si efectivamente aplica un reembolso, de acuerdo a las pol√≠ticas de la empresa. Aqu√≠ hay seis ejemplos de solicitudes de reembolso por varias razones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d42105",
   "metadata": {},
   "outputs": [],
   "source": [
    "refunds = \"\"\"\n",
    "---\n",
    "User: Jack\n",
    "Text: The description of the product stated that the socks were made primarily of cotton with a bit of spandex. The product I received indicated that the socks were made of primarily of polyester and a tiny bit of spandex. I wanted cotton socks so I returned the product. Several attempts to contact the supplier went unanswered and I still have not received a refund on my credit card. I need a solution and want a refund.\n",
    "\n",
    "---\n",
    "User: Tom\n",
    "Text: When I received my purchase, the package was open and significantly damaged. After unpacking it, I found that the shirt was dirty and had several scratches. I want to return and have a new unit sent to me.\n",
    "\n",
    "--- \n",
    "User: Bob\n",
    "Text: I ordered an XL just as my other Columbia jackets but this one is basically a XXL. The jacket is also extremely long for no reason. I want to return it.\n",
    "\n",
    "--- \n",
    "User: Shara\n",
    "Text: The jacket looks really nice and is warm but the sizing chart is completely off. I would normally be a large to extra large because of wide shoulders and back (I matched the large I'm the size chart). However, after using it a week I can say I need to go a size down or maybe even 2. Can I change it for a medium size?\n",
    "\n",
    "---\n",
    "User: Sasha\n",
    "Text: This jacket is incredibly warm and solidly built. However, they charged my credit card twice, so I am writing to get a refund of the second charge. Thanks in advance.\n",
    "\n",
    "---\n",
    "\n",
    "User: Chris\n",
    "Text: I bought this backpack for my children because the capacity and solid construction look. However after 2 weeks of school is completely demolished. Poor quality materials and broken zips. I want a refund.\n",
    "\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650382ee",
   "metadata": {},
   "source": [
    "Para aquellos que no han tenido la alegr√≠a de recibir un producto da√±ado, las condiciones de devoluci√≥n y reembolso no son especialmente f√°ciles de leer, con muchas reglas para casos espec√≠ficos y mucha letra chica. Por ejemplo, imaginemos que la pol√≠tica de devoluci√≥n y reembolso de nuestro sitio de comercio electr√≥nico se reduce a las siguientes cuatro reglas (en un escenario real, ser√≠an mucho m√°s que cuatro reglas).\n",
    "\n",
    "1. El cliente recibi√≥ el producto da√±ado o en malas condiciones.\n",
    "2. El cliente recibi√≥ el talle equivocado o un producto diferente. El producto debe estar todav√≠a en el paquete original y sin uso.\n",
    "3. El cliente no est√° satisfecho con el producto y desea cambiarlo. El producto debe estar todav√≠a en el paquete original y sin uso.\n",
    "4. Al cliente se le cobr√≥ m√°s de una vez en su tarjeta de cr√©dito el importe de la compra.\n",
    "\n",
    "Bajo estas condiciones, las solicitudes de Shara y Chris no son elegibles para un reembolso ya que sacaron el producto de su empaque original e incluso la usaron por un tiempo. Las condiciones establecen claramente que los productos deben estar en su embalaje original y no deben tener uso. En las restantes solicitudes aplica un reembolso.\n",
    "\n",
    "Ahora que tenemos las reglas, vamos a dise√±ar un prompt para indicarle al modelo que procese las solicitudes de reembolso. La idea es seguir un proceso de razonamiento paso a paso y llegar a una conclusi√≥n basada en el conjunto de reglas en lugar de simplemente adivinar. Si√©ntete libre de probar este prompt e incluso modificarlo para seguir un proceso de razonamiento diferente. Ten en cuenta que este es un buen ejemplo tambi√©n para proporcionar ejemplos reales como parte del prompt (few-shot-prompting) y aprovechar de las capacidades de aprendizaje del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf6fce",
   "metadata": {},
   "source": [
    "**Prompt üí¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02eb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You will be provided with a list of user complaints delimited by <>, who want a refund of their purchase for different reasons. \n",
    "Your task is to determine if corresponds or not, to give the customer a refund based on the company policy.\n",
    "\n",
    "Refunds policies\n",
    "\n",
    "Only apply a refund in the following scenarios:\n",
    "- The customer received the product with damages or in poor conditions\n",
    "- The customer received the wrong size or other product. The product must be still in the original package without usage.\n",
    "- The customer is not satisfied with the product and wishes to change it. The product must be still in the original package without usage.\n",
    "- The customer was charged more than once in his credit card.\n",
    "\n",
    "To solve the problem do the following:\n",
    "\n",
    "1 - Analyze whether the purchase applies the refunds policy based on the reasons given by the customer.\n",
    "2 - Categorize the case in: \"apply\" or \"not apply\" based on your previous judgment.\n",
    "3 - Provide a concise and personalized response with the reasons for your previous solution.\n",
    "5 - Output a json list object that contains the \n",
    "  following keys for each case: category, answer.\n",
    "\n",
    "Tickets: <{refunds}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac0727",
   "metadata": {},
   "source": [
    "Como podemos ver en la respuesta, GPT-4 resuelve correctamente cada caso, aportando para cada uno una justificaci√≥n acorde, se√±alando los motivos por los que NO aplica la devoluci√≥n. Seguramente sea necesario probar en un conjunto de datos m√°s grande y representativo antes de apresurarse a concluir que LLM puede manejar perfectamente esta tarea. Sin embargo, los resultados son muy alentadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134ad64",
   "metadata": {},
   "source": [
    "**Response ü§ñ** &nbsp;&nbsp;<span class=\"label success\">GPT-4</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83c27d",
   "metadata": {},
   "source": [
    "```python\n",
    "[\n",
    "  {\n",
    "    \"category\": \"apply\",\n",
    "    \"answer\": \"Dear Jack, we apologize for the inconvenience caused. Since you received a product with a different material than described and have already returned it, you are eligible for a refund. We will process your refund as soon as possible.\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"apply\",\n",
    "    \"answer\": \"Dear Tom, we're sorry to hear that the product arrived damaged and dirty. As per our refund policy, you are eligible for a replacement. Please return the damaged shirt, and we will send you a new one.\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"apply\",\n",
    "    \"answer\": \"Dear Bob, we apologize for the sizing issue you experienced. As you haven't used the jacket and it's still in the original package, you can return it. We will process your refund or exchange it for the correct size upon receiving the returned item.\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"not apply\",\n",
    "    \"answer\": \"Dear Shara, we appreciate your feedback on the sizing chart. However, since you have already used the jacket for a week, we cannot process an exchange or refund. We recommend referring to the sizing chart and contacting us before making future purchases to ensure a better fit.\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"apply\",\n",
    "    \"answer\": \"Dear Sasha, we apologize for the double charge on your credit card. We will refund the second charge immediately. Thank you for bringing this to our attention.\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"not apply\",\n",
    "    \"answer\": \"Dear Chris, we're sorry to hear that the backpack didn't meet your expectations. However, as the item has been used for two weeks, our refund policy does not apply in this case. We encourage you to read our refund policies carefully before making future purchases.\"\n",
    "  }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3367b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"category\": \"not apply\",\n",
      "    \"answer\": \"Based on the company's refund policy, a refund does not apply in this case. The reason for this is that the customer's complaint is about the product not meeting their personal preference in terms of material composition, which does not fall under the eligible reasons for a refund.\"\n",
      "  },\n",
      "  {\n",
      "    \"category\": \"apply\",\n",
      "    \"answer\": \"Based on the company's refund policy, a refund applies in this case. The customer received the product with damages and in poor conditions, which is one of the eligible reasons for a refund. They can return the product and request a new unit.\"\n",
      "  },\n",
      "  {\n",
      "    \"category\": \"apply\",\n",
      "    \"answer\": \"Based on the company's refund policy, a refund applies in this case. The customer received the wrong size and the product is still in the original package without usage, which is one of the eligible reasons for a refund. They can return the product and request the correct size.\"\n",
      "  },\n",
      "  {\n",
      "    \"category\": \"apply\",\n",
      "    \"answer\": \"Based on the company's refund policy, a refund applies in this case. The customer is not satisfied with the product and wishes to change it, and the product is still in the original package without usage, which is one of the eligible reasons for a refund. They can return the product and request a size change.\"\n",
      "  },\n",
      "  {\n",
      "    \"category\": \"apply\",\n",
      "    \"answer\": \"Based on the company's refund policy, a refund applies in this case. The customer was charged more than once in their credit card, which is one of the eligible reasons for a refund. They can request a refund for the second charge.\"\n",
      "  },\n",
      "  {\n",
      "    \"category\": \"not apply\",\n",
      "    \"answer\": \"Based on the company's refund policy, a refund does not apply in this case. The reason for this is that the customer's complaint is about the product not meeting their expectations in terms of durability, which is subjective and not covered by the eligible reasons for a refund.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Now is your turn!\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5000710",
   "metadata": {},
   "source": [
    "## Tercer Principio: Balancear especificidad y creatividad\n",
    "<a class=\"anchor\" id=\"allow-creativity\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5b25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e6004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8b790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6998b325",
   "metadata": {},
   "source": [
    "## Consejos √∫tiles\n",
    "<a class=\"anchor\" id=\"tips-and-tricks\"></a>\n",
    "\n",
    "üîù [Ir al √çndice](#index)\n",
    "\n",
    "The principles can help you as a general guide to writing clear and effective prompts. In addition, the following tips & tricks can help you optimize your prompts even more.\n",
    "\n",
    "Los 3 principios van a ayudarte como una gu√≠a general para escribir instrucciones claras y efectivas. Adicionalmente, los siguientes consejos y trucos pueden resultarte de gran ayuda tambi√©n:\n",
    "\n",
    "**1- Iterar**\n",
    "\n",
    "No existe tal cosa como un prompt perfecto, as√≠ que ve de una a probar el modelo con un prompt simple e imperfecto y luego has cambios y repite la ejecuci√≥n: repetir, repetir, repetir. Puedes seguir un ciclo de cuatro pasos: (i) escribir tu prompt, (ii) ejecutarlo, (iii) analizar el/los error/es, (iv) encontrar mejoras y repetir el ciclo.\n",
    "\n",
    "\n",
    "**2- Ser expl√≠cito y utilizar lenguaje objetivo**\n",
    "\n",
    "Las palabras que no tienen un significado claro o cuyo significado puede ser subjetivo pueden llevar al modelo a confundirse. Por ejemplo, como parte de una instrucci√≥n, solicitar volver a escribir un texto de usuario para que se vea mejor. ¬øQu√© significa verse mejor? En su lugar, es preferible indicar de forma expl√≠cita c√≥mo queremos mejorar el texto: limitar la extensi√≥n total a 50 palabras, corregir errores gramaticales, evitar lenguaje personal, etc.\n",
    "\n",
    "\n",
    "**3- Enumerar las instrucciones**\n",
    "\n",
    "En lugar de escribir un p√°rrafo largo con instrucciones complejas, div√≠dalo en instrucciones simples y enumerarlas.\n",
    "\n",
    "\n",
    "**4- Evitar afirmaciones negadas**\n",
    "\n",
    "Trate de evitar sentencias de negaci√≥n, a veces puede llevar el modelo a confusiones. En su lugar, convertirlas en sentencias afirmativas. Por ejemplo, en lugar de escribir _‚Äú**no** utilice expresiones de lenguaje mis√≥gino o sexista‚Äù_, escribir _‚Äú**usar** lenguaje inclusivo y respetuoso‚Äù_.\n",
    "\n",
    "\n",
    "**5- Reemplazar palabras**\n",
    "\n",
    "Algunas palabras pueden ser m√°s efectivas que otras, en t√©rminos de contextualizar y gyuar al modelo en la direcci√≥n correcta. Si tu prompt no esta dando los resultados esperados, trat√° de reemplazar palabras importantes por sin√≥nimos, siempre optando en favor de palabras m√°s simples y frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ca210f",
   "metadata": {},
   "source": [
    "**6- Prompt Perfect**\n",
    "\n",
    "Siempre podes escribir buenos prompts desde cero siguiendo los principios y buenas pr√°cticas o tambi√©n podes basarte en ejemplos de prompts ya hechos por alguien m√°s. Por ejemplo [PromptPerfect](https://promptperfect.jina.ai/) ofrece una basta colecci√≥n de Prompts ya dise√±ados por alguien m√°s, al igual que una herramienta potenciada por AI que te permite tomar tu prompt \"borrador\" y optimizarlo para diferentes LLMs agregando instrucciones m√°s claras y contexto. Algunas de las LLM soportadas son GPT-3, GPT-4, Midjourney, entre otras.\n",
    "\n",
    "\n",
    "Si hablamos de templates de prompts, tambi√©n tenemos que mencionar a los siguientes repositorios:\n",
    "\n",
    "\n",
    "‚û°Ô∏è [500+ ChatGPT Prompt Templates](https://ignacio-velasquez.notion.site/500-ChatGPT-Prompt-Templates-d9541e901b2b4e8f800e819bdc0256da)\n",
    "\n",
    "‚û°Ô∏è [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts/blob/main/prompts.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01069962",
   "metadata": {},
   "source": [
    "Como consejo final, la vida no es solo sobre prompting! A que me refiero, es tan importante conocer y entender el modelo que estamos utlizando, como funciona, si acepta par√°metros extra como parte del prompt (esto es muy comun en modeos `text-to-image` como Midjourney), como conocer las t√©cnicas y principios detra≈õ de un buen prompt. Por ejemplo, podemos ajustar el nivel de \"creatividad\" de un modelo como `ChatGPT` simplemente variando los par√°metros `temperature` y `top_p`. ¬øLo sab√≠as?\n",
    "\n",
    "En conclusi√≥n, no te olvides nunca de leer la documentaci√≥n!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdabf7a",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "<a class=\"anchor\" id=\"references\"></a>\n",
    "\n",
    "* [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)\n",
    "\n",
    "* [The Full Stack LLM Bootcamp](https://fullstackdeeplearning.com/llm-bootcamp/)\n",
    "\n",
    "* [OpenAI Playground](https://platform.openai.com/playground)\n",
    "\n",
    "* [OpenAI Cookbook](https://github.com/openai/openai-cookbook)\n",
    "\n",
    "* [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)\n",
    "\n",
    "* [Holtzman, A., Buys, J., Du, L., Forbes, M., & Choi, Y. (2019). The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751.](https://arxiv.org/abs/1904.09751)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-engineering",
   "language": "python",
   "name": "prompt-engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
